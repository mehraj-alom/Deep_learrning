{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12383209,"sourceType":"datasetVersion","datasetId":7808375}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.891239Z","iopub.execute_input":"2025-07-05T18:27:47.891765Z","iopub.status.idle":"2025-07-05T18:27:47.899207Z","shell.execute_reply.started":"2025-07-05T18:27:47.891730Z","shell.execute_reply":"2025-07-05T18:27:47.898385Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sonar-dataset/sonar_dataset.csv\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\ndf = pd.read_csv(\"/kaggle/input/sonar-dataset/sonar_dataset.csv\",header=None)\ndf.tail(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.900587Z","iopub.execute_input":"2025-07-05T18:27:47.900856Z","iopub.status.idle":"2025-07-05T18:27:47.939997Z","shell.execute_reply.started":"2025-07-05T18:27:47.900829Z","shell.execute_reply":"2025-07-05T18:27:47.939125Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"         0       1       2       3       4       5       6       7       8   \\\n203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n\n         9   ...      51      52      53      54      55      56      57  \\\n203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n\n         58      59  60  \n203  0.0193  0.0157   M  \n204  0.0062  0.0067   M  \n205  0.0077  0.0031   M  \n206  0.0036  0.0048   M  \n207  0.0061  0.0115   M  \n\n[5 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>203</th>\n      <td>0.0187</td>\n      <td>0.0346</td>\n      <td>0.0168</td>\n      <td>0.0177</td>\n      <td>0.0393</td>\n      <td>0.1630</td>\n      <td>0.2028</td>\n      <td>0.1694</td>\n      <td>0.2328</td>\n      <td>0.2684</td>\n      <td>...</td>\n      <td>0.0116</td>\n      <td>0.0098</td>\n      <td>0.0199</td>\n      <td>0.0033</td>\n      <td>0.0101</td>\n      <td>0.0065</td>\n      <td>0.0115</td>\n      <td>0.0193</td>\n      <td>0.0157</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>0.0323</td>\n      <td>0.0101</td>\n      <td>0.0298</td>\n      <td>0.0564</td>\n      <td>0.0760</td>\n      <td>0.0958</td>\n      <td>0.0990</td>\n      <td>0.1018</td>\n      <td>0.1030</td>\n      <td>0.2154</td>\n      <td>...</td>\n      <td>0.0061</td>\n      <td>0.0093</td>\n      <td>0.0135</td>\n      <td>0.0063</td>\n      <td>0.0063</td>\n      <td>0.0034</td>\n      <td>0.0032</td>\n      <td>0.0062</td>\n      <td>0.0067</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>0.0522</td>\n      <td>0.0437</td>\n      <td>0.0180</td>\n      <td>0.0292</td>\n      <td>0.0351</td>\n      <td>0.1171</td>\n      <td>0.1257</td>\n      <td>0.1178</td>\n      <td>0.1258</td>\n      <td>0.2529</td>\n      <td>...</td>\n      <td>0.0160</td>\n      <td>0.0029</td>\n      <td>0.0051</td>\n      <td>0.0062</td>\n      <td>0.0089</td>\n      <td>0.0140</td>\n      <td>0.0138</td>\n      <td>0.0077</td>\n      <td>0.0031</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>0.0303</td>\n      <td>0.0353</td>\n      <td>0.0490</td>\n      <td>0.0608</td>\n      <td>0.0167</td>\n      <td>0.1354</td>\n      <td>0.1465</td>\n      <td>0.1123</td>\n      <td>0.1945</td>\n      <td>0.2354</td>\n      <td>...</td>\n      <td>0.0086</td>\n      <td>0.0046</td>\n      <td>0.0126</td>\n      <td>0.0036</td>\n      <td>0.0035</td>\n      <td>0.0034</td>\n      <td>0.0079</td>\n      <td>0.0036</td>\n      <td>0.0048</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>0.0260</td>\n      <td>0.0363</td>\n      <td>0.0136</td>\n      <td>0.0272</td>\n      <td>0.0214</td>\n      <td>0.0338</td>\n      <td>0.0655</td>\n      <td>0.1400</td>\n      <td>0.1843</td>\n      <td>0.2354</td>\n      <td>...</td>\n      <td>0.0146</td>\n      <td>0.0129</td>\n      <td>0.0047</td>\n      <td>0.0039</td>\n      <td>0.0061</td>\n      <td>0.0040</td>\n      <td>0.0036</td>\n      <td>0.0061</td>\n      <td>0.0115</td>\n      <td>M</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.940771Z","iopub.execute_input":"2025-07-05T18:27:47.940995Z","iopub.status.idle":"2025-07-05T18:27:47.946644Z","shell.execute_reply.started":"2025-07-05T18:27:47.940977Z","shell.execute_reply":"2025-07-05T18:27:47.945901Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"(208, 61)"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"df[60] = df[60].apply(lambda x : 1 if x == \"M\" else 0)\ndf.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.948290Z","iopub.execute_input":"2025-07-05T18:27:47.948794Z","iopub.status.idle":"2025-07-05T18:27:47.980605Z","shell.execute_reply.started":"2025-07-05T18:27:47.948772Z","shell.execute_reply":"2025-07-05T18:27:47.979769Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"         0       1       2       3       4       5       6       7       8   \\\n205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n45   0.0408  0.0653  0.0397  0.0604  0.0496  0.1817  0.1178  0.1024  0.0583   \n56   0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n40   0.0068  0.0232  0.0513  0.0444  0.0249  0.0637  0.0422  0.1130  0.1911   \n193  0.0203  0.0121  0.0380  0.0128  0.0537  0.0874  0.1021  0.0852  0.1136   \n167  0.0137  0.0297  0.0116  0.0082  0.0241  0.0253  0.0279  0.0130  0.0489   \n70   0.0065  0.0122  0.0068  0.0108  0.0217  0.0284  0.0527  0.0575  0.1054   \n140  0.0412  0.1135  0.0518  0.0232  0.0646  0.1124  0.1787  0.2407  0.2682   \n67   0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n170  0.0134  0.0172  0.0178  0.0363  0.0444  0.0744  0.0800  0.0456  0.0368   \n\n         9   ...      51      52      53      54      55      56      57  \\\n205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n45   0.2176  ...  0.0062  0.0129  0.0184  0.0069  0.0198  0.0199  0.0102   \n56   0.1504  ...  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037  0.0011   \n40   0.2475  ...  0.0173  0.0163  0.0055  0.0045  0.0068  0.0041  0.0052   \n193  0.1747  ...  0.0134  0.0094  0.0047  0.0045  0.0042  0.0028  0.0036   \n167  0.0874  ...  0.0081  0.0040  0.0025  0.0036  0.0058  0.0067  0.0035   \n70   0.1109  ...  0.0069  0.0025  0.0027  0.0052  0.0036  0.0026  0.0036   \n140  0.2058  ...  0.0376  0.0143  0.0272  0.0127  0.0166  0.0095  0.0225   \n67   0.0506  ...  0.0091  0.0160  0.0160  0.0081  0.0070  0.0135  0.0067   \n170  0.1250  ...  0.0094  0.0048  0.0047  0.0016  0.0008  0.0042  0.0024   \n\n         58      59  60  \n205  0.0077  0.0031   1  \n45   0.0070  0.0055   0  \n56   0.0034  0.0033   0  \n40   0.0194  0.0105   0  \n193  0.0013  0.0016   1  \n167  0.0043  0.0033   1  \n70   0.0006  0.0035   0  \n140  0.0098  0.0085   1  \n67   0.0078  0.0068   0  \n170  0.0027  0.0041   1  \n\n[10 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>205</th>\n      <td>0.0522</td>\n      <td>0.0437</td>\n      <td>0.0180</td>\n      <td>0.0292</td>\n      <td>0.0351</td>\n      <td>0.1171</td>\n      <td>0.1257</td>\n      <td>0.1178</td>\n      <td>0.1258</td>\n      <td>0.2529</td>\n      <td>...</td>\n      <td>0.0160</td>\n      <td>0.0029</td>\n      <td>0.0051</td>\n      <td>0.0062</td>\n      <td>0.0089</td>\n      <td>0.0140</td>\n      <td>0.0138</td>\n      <td>0.0077</td>\n      <td>0.0031</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.0408</td>\n      <td>0.0653</td>\n      <td>0.0397</td>\n      <td>0.0604</td>\n      <td>0.0496</td>\n      <td>0.1817</td>\n      <td>0.1178</td>\n      <td>0.1024</td>\n      <td>0.0583</td>\n      <td>0.2176</td>\n      <td>...</td>\n      <td>0.0062</td>\n      <td>0.0129</td>\n      <td>0.0184</td>\n      <td>0.0069</td>\n      <td>0.0198</td>\n      <td>0.0199</td>\n      <td>0.0102</td>\n      <td>0.0070</td>\n      <td>0.0055</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>0.0152</td>\n      <td>0.0102</td>\n      <td>0.0113</td>\n      <td>0.0263</td>\n      <td>0.0097</td>\n      <td>0.0391</td>\n      <td>0.0857</td>\n      <td>0.0915</td>\n      <td>0.0949</td>\n      <td>0.1504</td>\n      <td>...</td>\n      <td>0.0049</td>\n      <td>0.0041</td>\n      <td>0.0036</td>\n      <td>0.0013</td>\n      <td>0.0046</td>\n      <td>0.0037</td>\n      <td>0.0011</td>\n      <td>0.0034</td>\n      <td>0.0033</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.0068</td>\n      <td>0.0232</td>\n      <td>0.0513</td>\n      <td>0.0444</td>\n      <td>0.0249</td>\n      <td>0.0637</td>\n      <td>0.0422</td>\n      <td>0.1130</td>\n      <td>0.1911</td>\n      <td>0.2475</td>\n      <td>...</td>\n      <td>0.0173</td>\n      <td>0.0163</td>\n      <td>0.0055</td>\n      <td>0.0045</td>\n      <td>0.0068</td>\n      <td>0.0041</td>\n      <td>0.0052</td>\n      <td>0.0194</td>\n      <td>0.0105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>0.0203</td>\n      <td>0.0121</td>\n      <td>0.0380</td>\n      <td>0.0128</td>\n      <td>0.0537</td>\n      <td>0.0874</td>\n      <td>0.1021</td>\n      <td>0.0852</td>\n      <td>0.1136</td>\n      <td>0.1747</td>\n      <td>...</td>\n      <td>0.0134</td>\n      <td>0.0094</td>\n      <td>0.0047</td>\n      <td>0.0045</td>\n      <td>0.0042</td>\n      <td>0.0028</td>\n      <td>0.0036</td>\n      <td>0.0013</td>\n      <td>0.0016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>0.0137</td>\n      <td>0.0297</td>\n      <td>0.0116</td>\n      <td>0.0082</td>\n      <td>0.0241</td>\n      <td>0.0253</td>\n      <td>0.0279</td>\n      <td>0.0130</td>\n      <td>0.0489</td>\n      <td>0.0874</td>\n      <td>...</td>\n      <td>0.0081</td>\n      <td>0.0040</td>\n      <td>0.0025</td>\n      <td>0.0036</td>\n      <td>0.0058</td>\n      <td>0.0067</td>\n      <td>0.0035</td>\n      <td>0.0043</td>\n      <td>0.0033</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.0065</td>\n      <td>0.0122</td>\n      <td>0.0068</td>\n      <td>0.0108</td>\n      <td>0.0217</td>\n      <td>0.0284</td>\n      <td>0.0527</td>\n      <td>0.0575</td>\n      <td>0.1054</td>\n      <td>0.1109</td>\n      <td>...</td>\n      <td>0.0069</td>\n      <td>0.0025</td>\n      <td>0.0027</td>\n      <td>0.0052</td>\n      <td>0.0036</td>\n      <td>0.0026</td>\n      <td>0.0036</td>\n      <td>0.0006</td>\n      <td>0.0035</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>0.0412</td>\n      <td>0.1135</td>\n      <td>0.0518</td>\n      <td>0.0232</td>\n      <td>0.0646</td>\n      <td>0.1124</td>\n      <td>0.1787</td>\n      <td>0.2407</td>\n      <td>0.2682</td>\n      <td>0.2058</td>\n      <td>...</td>\n      <td>0.0376</td>\n      <td>0.0143</td>\n      <td>0.0272</td>\n      <td>0.0127</td>\n      <td>0.0166</td>\n      <td>0.0095</td>\n      <td>0.0225</td>\n      <td>0.0098</td>\n      <td>0.0085</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.0368</td>\n      <td>0.0403</td>\n      <td>0.0317</td>\n      <td>0.0293</td>\n      <td>0.0820</td>\n      <td>0.1342</td>\n      <td>0.1161</td>\n      <td>0.0663</td>\n      <td>0.0155</td>\n      <td>0.0506</td>\n      <td>...</td>\n      <td>0.0091</td>\n      <td>0.0160</td>\n      <td>0.0160</td>\n      <td>0.0081</td>\n      <td>0.0070</td>\n      <td>0.0135</td>\n      <td>0.0067</td>\n      <td>0.0078</td>\n      <td>0.0068</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>0.0134</td>\n      <td>0.0172</td>\n      <td>0.0178</td>\n      <td>0.0363</td>\n      <td>0.0444</td>\n      <td>0.0744</td>\n      <td>0.0800</td>\n      <td>0.0456</td>\n      <td>0.0368</td>\n      <td>0.1250</td>\n      <td>...</td>\n      <td>0.0094</td>\n      <td>0.0048</td>\n      <td>0.0047</td>\n      <td>0.0016</td>\n      <td>0.0008</td>\n      <td>0.0042</td>\n      <td>0.0024</td>\n      <td>0.0027</td>\n      <td>0.0041</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 61 columns</p>\n</div>"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"df[60].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.981564Z","iopub.execute_input":"2025-07-05T18:27:47.981869Z","iopub.status.idle":"2025-07-05T18:27:47.996831Z","shell.execute_reply.started":"2025-07-05T18:27:47.981841Z","shell.execute_reply":"2025-07-05T18:27:47.996077Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"array([0, 1])"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"X = df.drop(60,axis=\"columns\")\ny = df[60]\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=32,stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:47.997868Z","iopub.execute_input":"2025-07-05T18:27:47.998155Z","iopub.status.idle":"2025-07-05T18:27:48.012686Z","shell.execute_reply.started":"2025-07-05T18:27:47.998130Z","shell.execute_reply":"2025-07-05T18:27:48.011907Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:48.013563Z","iopub.execute_input":"2025-07-05T18:27:48.013798Z","iopub.status.idle":"2025-07-05T18:27:48.026828Z","shell.execute_reply.started":"2025-07-05T18:27:48.013779Z","shell.execute_reply":"2025-07-05T18:27:48.026066Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"(166, 60)"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:48.027708Z","iopub.execute_input":"2025-07-05T18:27:48.028008Z","iopub.status.idle":"2025-07-05T18:27:48.041290Z","shell.execute_reply.started":"2025-07-05T18:27:48.027983Z","shell.execute_reply":"2025-07-05T18:27:48.040391Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"(42, 60)"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"#Without Regulariation\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.Sequential([\n    keras.layers.Dense(60,input_shape=(60,),activation=\"relu\"),\n    keras.layers.Dense(20,activation=\"relu\"),\n    keras.layers.Dense(1,activation=\"sigmoid\")\n])\n\nmodel.compile(\n    loss = \"binary_crossentropy\",\n    optimizer=\"adam\",\n    metrics = [\"accuracy\"]\n)\n\nmodel.fit(X_train,y_train,epochs=100,batch_size=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:48.043950Z","iopub.execute_input":"2025-07-05T18:27:48.044208Z","iopub.status.idle":"2025-07-05T18:27:56.755058Z","shell.execute_reply.started":"2025-07-05T18:27:48.044189Z","shell.execute_reply":"2025-07-05T18:27:56.754278Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5421 - loss: 0.6832\nEpoch 2/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 0.6470 \nEpoch 3/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.6207 \nEpoch 4/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.5942 \nEpoch 5/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5471 \nEpoch 6/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.5136 \nEpoch 7/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5070 \nEpoch 8/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7892 - loss: 0.4651 \nEpoch 9/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.4099 \nEpoch 10/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4155 \nEpoch 11/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3898 \nEpoch 12/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3436 \nEpoch 13/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.3553 \nEpoch 14/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3418 \nEpoch 15/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.3485 \nEpoch 16/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.3144 \nEpoch 17/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3301 \nEpoch 18/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2852 \nEpoch 19/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3311 \nEpoch 20/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3214 \nEpoch 21/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2766 \nEpoch 22/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2640 \nEpoch 23/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.2844 \nEpoch 24/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2526 \nEpoch 25/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2465 \nEpoch 26/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2458 \nEpoch 27/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2543 \nEpoch 28/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2439 \nEpoch 29/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2493 \nEpoch 30/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2259 \nEpoch 31/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2421 \nEpoch 32/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2350 \nEpoch 33/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2105 \nEpoch 34/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.1914 \nEpoch 35/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2257 \nEpoch 36/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2137 \nEpoch 37/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.1730 \nEpoch 38/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1594 \nEpoch 39/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1768 \nEpoch 40/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1521 \nEpoch 41/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1778 \nEpoch 42/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.1317 \nEpoch 43/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1367 \nEpoch 44/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1373 \nEpoch 45/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.1152 \nEpoch 46/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.1165 \nEpoch 47/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1385 \nEpoch 48/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.1063 \nEpoch 49/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.1098 \nEpoch 50/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.1236 \nEpoch 51/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.1052 \nEpoch 52/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0917 \nEpoch 53/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.1192 \nEpoch 54/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.1042 \nEpoch 55/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1039 \nEpoch 56/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0930 \nEpoch 57/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0981 \nEpoch 58/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.1062 \nEpoch 59/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0723 \nEpoch 60/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0803 \nEpoch 61/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0624 \nEpoch 62/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0782 \nEpoch 63/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0873 \nEpoch 64/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0677 \nEpoch 65/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.1211 \nEpoch 66/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0618 \nEpoch 67/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0633 \nEpoch 68/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0692 \nEpoch 69/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0544 \nEpoch 70/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0708 \nEpoch 71/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0470 \nEpoch 72/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0565 \nEpoch 73/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0509 \nEpoch 74/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0535 \nEpoch 75/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0449 \nEpoch 76/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0509 \nEpoch 77/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0415 \nEpoch 78/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0394 \nEpoch 79/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0656 \nEpoch 80/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0407 \nEpoch 81/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0442 \nEpoch 82/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0347 \nEpoch 83/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0320 \nEpoch 84/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0317 \nEpoch 85/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0338 \nEpoch 86/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0300 \nEpoch 87/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0241 \nEpoch 88/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0471 \nEpoch 89/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0323 \nEpoch 90/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0342 \nEpoch 91/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0258 \nEpoch 92/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0252 \nEpoch 93/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0239 \nEpoch 94/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0270 \nEpoch 95/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0221 \nEpoch 96/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0239 \nEpoch 97/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0375 \nEpoch 98/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0296 \nEpoch 99/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0229 \nEpoch 100/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0222 \n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79cdf81c9990>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"model.evaluate(X_test,y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:56.755889Z","iopub.execute_input":"2025-07-05T18:27:56.756272Z","iopub.status.idle":"2025-07-05T18:27:57.038885Z","shell.execute_reply.started":"2025-07-05T18:27:56.756235Z","shell.execute_reply":"2025-07-05T18:27:57.038151Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8313 - loss: 0.7875 \n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"[0.8309393525123596, 0.8095238208770752]"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"y_pred = model.predict(X_test).reshape(-1)\nprint(y_pred[:10])\n\n# round the values to nearest integer ie 0 or 1\ny_pred = np.round(y_pred)\nprint(y_pred[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:57.039708Z","iopub.execute_input":"2025-07-05T18:27:57.040006Z","iopub.status.idle":"2025-07-05T18:27:57.220574Z","shell.execute_reply.started":"2025-07-05T18:27:57.039981Z","shell.execute_reply":"2025-07-05T18:27:57.219781Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n[2.9674703e-03 9.9999624e-01 9.7850436e-01 9.9644893e-01 8.2372702e-05\n 2.8582413e-02 9.8895442e-01 7.6040874e-07 7.8711912e-02 8.1545687e-01]\n[0. 1. 1. 1. 0. 0. 1. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\n\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:57.221341Z","iopub.execute_input":"2025-07-05T18:27:57.221593Z","iopub.status.idle":"2025-07-05T18:27:57.234731Z","shell.execute_reply.started":"2025-07-05T18:27:57.221574Z","shell.execute_reply":"2025-07-05T18:27:57.233857Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.77      0.85      0.81        20\n           1       0.85      0.77      0.81        22\n\n    accuracy                           0.81        42\n   macro avg       0.81      0.81      0.81        42\nweighted avg       0.81      0.81      0.81        42\n\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"#With Regulerization\nmodel_d = keras.Sequential([\n    keras.layers.Dense(60,input_shape=(60,),activation=\"relu\"),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(20,activation=\"relu\"),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(1,activation=\"sigmoid\")\n])\n\nmodel_d.compile(\n    loss = \"binary_crossentropy\",\n    optimizer=\"adam\",\n    metrics = [\"accuracy\"]\n)\n\nmodel_d.fit(X_train,y_train,epochs=100,batch_size=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:27:57.235815Z","iopub.execute_input":"2025-07-05T18:27:57.236028Z","iopub.status.idle":"2025-07-05T18:28:06.805938Z","shell.execute_reply.started":"2025-07-05T18:27:57.236012Z","shell.execute_reply":"2025-07-05T18:28:06.805231Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4194 - loss: 0.7090\nEpoch 2/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5381 - loss: 0.6931 \nEpoch 3/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 0.6389 \nEpoch 4/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 0.6905 \nEpoch 5/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5910 - loss: 0.6496 \nEpoch 6/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.6426 \nEpoch 7/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.5883 \nEpoch 8/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6777 - loss: 0.6129 \nEpoch 9/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5667 \nEpoch 10/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7512 - loss: 0.5381 \nEpoch 11/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5221 \nEpoch 12/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4949 \nEpoch 13/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.5194 \nEpoch 14/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4903 \nEpoch 15/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7842 - loss: 0.5215 \nEpoch 16/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4421 \nEpoch 17/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.4159 \nEpoch 18/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7539 - loss: 0.4821 \nEpoch 19/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.4157 \nEpoch 20/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.4311 \nEpoch 21/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4108 \nEpoch 22/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.3876 \nEpoch 23/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5116 \nEpoch 24/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.4141 \nEpoch 25/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.4207 \nEpoch 26/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3797 \nEpoch 27/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3384 \nEpoch 28/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.3327 \nEpoch 29/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.3868 \nEpoch 30/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.3151 \nEpoch 31/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4116 \nEpoch 32/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.3707 \nEpoch 33/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3847 \nEpoch 34/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2692 \nEpoch 35/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3536 \nEpoch 36/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.3001 \nEpoch 37/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3756 \nEpoch 38/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3242 \nEpoch 39/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2499 \nEpoch 40/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.3029 \nEpoch 41/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.3227 \nEpoch 42/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2783 \nEpoch 43/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2592 \nEpoch 44/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.2827 \nEpoch 45/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2406 \nEpoch 46/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.2864 \nEpoch 47/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.2839 \nEpoch 48/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2173 \nEpoch 49/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2788 \nEpoch 50/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2943 \nEpoch 51/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.2193 \nEpoch 52/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2824 \nEpoch 53/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2874 \nEpoch 54/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2683 \nEpoch 55/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2697 \nEpoch 56/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8774 - loss: 0.2446 \nEpoch 57/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.2724 \nEpoch 58/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2179 \nEpoch 59/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2623 \nEpoch 60/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2319 \n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2319 \n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1907 \nEpoch 62/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.2182 \nEpoch 63/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2026 \nEpoch 64/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2136 \nEpoch 65/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.2130 \nEpoch 66/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.2059 \nEpoch 67/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2206 \nEpoch 68/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1695 \nEpoch 69/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1892 \nEpoch 70/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2188 \nEpoch 71/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.1954 \nEpoch 72/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.1566 \nEpoch 73/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.1968 \nEpoch 74/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1563 \nEpoch 75/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1373 \nEpoch 76/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.1618 \nEpoch 77/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1715 \nEpoch 78/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1423 \nEpoch 79/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1247 \nEpoch 80/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1848 \nEpoch 81/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.1733 \nEpoch 82/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1266 \nEpoch 83/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1250 \nEpoch 84/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1191 \nEpoch 85/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.1009 \nEpoch 86/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.1029 \nEpoch 87/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.1589 \nEpoch 88/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1336 \nEpoch 89/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1199 \nEpoch 90/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0810 \nEpoch 91/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1113 \nEpoch 92/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1198 \nEpoch 93/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.0984 \nEpoch 94/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1185 \nEpoch 95/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.1637 \nEpoch 96/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1051 \nEpoch 97/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0817 \nEpoch 98/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.0936 \nEpoch 99/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0849 \nEpoch 100/100\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0968 \n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79cdd4292490>"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"y_pred = model_d.predict(X_test).reshape(-1)\nprint(y_pred[:10])\n\n# round the values to nearest integer ie 0 or 1\ny_pred = np.round(y_pred)\nprint(y_pred[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:28:06.806811Z","iopub.execute_input":"2025-07-05T18:28:06.807078Z","iopub.status.idle":"2025-07-05T18:28:06.985983Z","shell.execute_reply.started":"2025-07-05T18:28:06.807059Z","shell.execute_reply":"2025-07-05T18:28:06.985132Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n[4.4096354e-03 9.9996799e-01 9.7260201e-01 9.9145877e-01 2.9744082e-03\n 4.1434415e-02 9.5602608e-01 4.2983287e-05 8.4830530e-02 6.3166666e-01]\n[0. 1. 1. 1. 0. 0. 1. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\n\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:28:06.986923Z","iopub.execute_input":"2025-07-05T18:28:06.987507Z","iopub.status.idle":"2025-07-05T18:28:07.001314Z","shell.execute_reply.started":"2025-07-05T18:28:06.987479Z","shell.execute_reply":"2025-07-05T18:28:07.000578Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80        20\n           1       0.82      0.82      0.82        22\n\n    accuracy                           0.81        42\n   macro avg       0.81      0.81      0.81        42\nweighted avg       0.81      0.81      0.81        42\n\n","output_type":"stream"}],"execution_count":75}]}